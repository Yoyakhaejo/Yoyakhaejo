"""
Streamlit 페이지 1: 업로드된 자료(이미 업로드되어 세션/폴더에 저장된 PDF/PPT/텍스트)를 바탕으로
연습문제(객관식/주관식)를 생성하는 페이지

설치 필요 패키지(예시):
  pip install streamlit openai PyPDF2 python-pptx pandas

사용 가정(이 페이지는 "이미 올린 자료"가 앱의 uploads/ 폴더 또는 st.session_state['uploaded_files']에
저장되어 있다는 전제에서 동작합니다):
  - st.session_state['openai_api_key'] 에 사용자의 OpenAI API 키가 저장되어 있음.
  - st.session_state['uploaded_files'] 는 리스트로, 각각은 dict 형식: {'name': str, 'path': str, 'type': 'pdf'|'pptx'|'txt'|'transcript'}
    (파일 업로드 페이지에서 이를 만들어 두었다고 가정)

이 페이지는 다음 기능을 제공합니다:
  1) 업로드된 파일 목록을 불러와서 텍스트를 추출(지원: PDF, PPTX, TXT/MD)
  2) 텍스트를 합쳐서 간단 요약을 생성(옵션)
  3) 요약/원문을 바탕으로 연습문제 생성 (문제수/난이도/객관식 여부 선택 가능)
  4) 생성된 문제를 화면에 보여주고 CSV로 다운로드 가능

주의: MP4/동영상 파일에서 자동으로 좋은 품질의 자막을 얻으려면 별도의 음성인식(Whisper 등)이 필요합니다.
앱에서 서버사이드로 자동 변환을 구현할 수 있지만 이 코드는 간단히 "transcript" 파일(예: .txt, .srt)
또는 사용자가 미리 업로드한 텍스트를 우선 사용하도록 설계되어 있습니다.

"""

import streamlit as st
import openai
import os
from typing import List, Dict
import PyPDF2
from pptx import Presentation
import pandas as pd
import io
import json

st.set_page_config(page_title="연습문제 생성 (페이지 1)", layout="wide")

# ------------------------- 유틸리티 함수 -------------------------

def load_pdf_text(path: str) -> str:
    """PDF에서 텍스트를 추출합니다."""
    text_chunks = []
    try:
        with open(path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text_chunks.append(page_text)
    except Exception as e:
        st.warning(f"PDF 추출 실패: {path} — {e}")
    return "\n\n".join(text_chunks)


def load_pptx_text(path: str) -> str:
    """PPTX에서 텍스트를 추출합니다."""
    text_chunks = []
    try:
        prs = Presentation(path)
        for slide in prs.slides:
            slide_text = []
            for shp in slide.shapes:
                if hasattr(shp, "text"):
                    slide_text.append(shp.text)
            if slide_text:
                text_chunks.append("\n".join(slide_text))
    except Exception as e:
        st.warning(f"PPTX 추출 실패: {path} — {e}")
    return "\n\n".join(text_chunks)


def load_txt(path: str) -> str:
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception:
        try:
            with open(path, 'r', encoding='cp949') as f:
                return f.read()
        except Exception as e:
            st.warning(f"텍스트 파일 로드 실패: {path} — {e}")
            return ""


def aggregate_uploaded_text(upload_list: List[Dict]) -> str:
    """업로드 목록에서 지원되는 파일의 텍스트를 모두 합칩니다."""
    pieces = []
    for item in upload_list:
        p = item.get('path')
        t = item.get('type', '').lower()
        if not os.path.exists(p):
            st.warning(f"파일을 찾을 수 없음: {p}")
            continue
        if t == 'pdf':
            pieces.append(load_pdf_text(p))
        elif t == 'pptx':
            pieces.append(load_pptx_text(p))
        elif t in ('txt', 'md', 'transcript'):
            pieces.append(load_txt(p))
        else:
            st.info(f"지원하지 않는 타입(또는 변환 필요): {item.get('name')} — type={t}")
    return "\n\n".join([p for p in pieces if p])


# ------------------------- OpenAI 연동 -------------------------

def ensure_openai_key():
    key = None
    # 우선 세션 스테이트에 키가 있는지 확인
    if 'openai_api_key' in st.session_state and st.session_state['openai_api_key']:
        key = st.session_state['openai_api_key']
    # 환경변수 fallback
    if not key:
        key = os.environ.get('OPENAI_API_KEY')
    if not key:
        st.error("OpenAI API 키가 설정되어 있지 않습니다. (설정: 업로드 페이지에서 키를 입력하거나 환경변수 OPENAI_API_KEY 설정)")
        st.stop()
    openai.api_key = key


def call_gpt_generate_questions(context_text: str, num_questions: int = 5, difficulty: str = '중간', include_mcq: bool = True) -> List[Dict]:
    """
    GPT에 질문 생성을 요청합니다. 반환값은 질문 리스트(각 항목은 dict: {type, question, choices, answer, explanation})
    이 함수는 gpt-3.5-turbo를 사용합니다 (일반적으로 안정적인 모델).
    """
    ensure_openai_key()

    system_prompt = (
        "당신은 교육용 문제 출제 전문가입니다. 다음 본문을 읽고 요청한 형식으로 연습문제를 만들어주세요."
    )

    user_prompt = (
        f"본문:\n```\n{context_text[:3000]}\n```\n\n"
        f"요청사항:\n- 문제 수: {num_questions}\n- 난이도: {difficulty}\n- 객관식 포함: {'예' if include_mcq else '아니오'}\n\n"
        "출력 포맷(반드시 JSON): [\n  {\n    \"type\": \"mcq\" 또는 \"short_answer\",\n    \"question\": \"질문 내용\",\n    \"choices\": [\"보기1\", \"보기2\", ...] (객관식일 때만),\n    \"answer\": \"정답(간단)\",\n    \"explanation\": \"해설(간단)\"\n  }, ...\n]\n"
        "주의: JSON 외 추가 텍스트를 최소화하고, 반드시 유효한 JSON로 반환하세요."
    )

    # 모델 호출
    try:
        resp = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.2,
            max_tokens=1500
        )
        content = resp['choices'][0]['message']['content']
    except Exception as e:
        st.error(f"문제 생성 중 오류가 발생했습니다: {e}")
        return []

    # GPT가 내놓은 내용을 JSON으로 파싱 시도
    try:
        # 종종 GPT가 코드블럭을 붙여내려 할 수 있으므로 안전 조치
        # JSON이 텍스트 내에 있으면 먼저 `{`로 시작하는 위치 찾기
        start = content.find('[')
        if start != -1:
            json_text = content[start:]
        else:
            json_text = content
        questions = json.loads(json_text)
        return questions
    except Exception as e:
        st.warning(f"생성된 출력에서 JSON 파싱 실패: {e}")
        st.info("모델 출력(원문)을 확인하세요.")
        st.code(content)
        return []


# ------------------------- Streamlit UI -------------------------

st.title("페이지 1 — 업로드된 자료로 연습문제 만들기")

# 업로드된 파일 목록 가져오기 (가정)
uploaded_files = st.session_state.get('uploaded_files', None)

if not uploaded_files:
    st.info("현재 업로드된 자료가 없습니다. 먼저 자료 업로드 페이지에서 파일을 올려주세요.\n(또는 st.session_state['uploaded_files']에 파일 리스트를 넣어 테스트할 수 있습니다.)")
    st.stop()

# 왼쪽: 파일 목록, 요약 옵션
col1, col2 = st.columns([1, 2])
with col1:
    st.subheader("업로드된 자료")
    for i, it in enumerate(uploaded_files):
        st.write(f"{i+1}. {it.get('name')}  —  type: {it.get('type')}")

    with st.expander("텍스트 합치기/요약 옵션"):
        max_context_chars = st.slider("요약/문제 생성용 최대 텍스트 길이 (문자)", min_value=2000, max_value=20000, value=8000, step=500)
        auto_summarize = st.checkbox("긴 문서를 자동으로 요약해서 사용할래요? (권장)", value=True)

with col2:
    st.subheader("설정: 문제 생성")
    num_q = st.number_input("문제 수", min_value=1, max_value=30, value=5)
    difficulty = st.selectbox("난이도", options=["쉬움", "중간", "어려움"], index=1)
    include_mcq = st.checkbox("객관식 포함", value=True)
    generate_btn = st.button("문제 생성")

# 텍스트 합치기
with st.spinner('파일에서 텍스트 추출 중...'):
    combined_text = aggregate_uploaded_text(uploaded_files)

if not combined_text.strip():
    st.error("추출된 텍스트가 없습니다. 지원되는 파일 형식(PDF, PPTX, TXT 등)인지 확인하거나, 동영상에서 자막(트랜스크립트)을 업로드 해주세요.")
    st.stop()

# 자동 요약(선택)
if auto_summarize:
    ensure_openai_key()
    # 최대 문자 제한을 적용하여 컨텍스트 슬라이싱
    context_for_model = combined_text[:max_context_chars]
    try:
        # 간단 요약 요청
        sum_resp = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "당신은 요약 전문가입니다. 다음 본문을 3~6문장으로 간결하게 요약하세요."},
                {"role": "user", "content": f"본문:\n{context_for_model}"}
            ],
            temperature=0.2,
            max_tokens=400
        )
        summary_text = sum_resp['choices'][0]['message']['content'].strip()
    except Exception as e:
        st.warning(f"요약 생성 실패: {e}")
        summary_text = combined_text[:max_context_chars]
else:
    summary_text = combined_text[:max_context_chars]

st.markdown("---")
st.subheader("사용할 텍스트(요약 또는 원문 일부)")
with st.expander("요약/선택 텍스트 보기", expanded=False):
    st.write(summary_text[:10000])

# 문제 생성 실행
if generate_btn:
    with st.spinner('모델에게 문제 생성을 요청하는 중...'):
        questions = call_gpt_generate_questions(summary_text, num_questions=int(num_q), difficulty=difficulty, include_mcq=include_mcq)

    if not questions:
        st.error("문제 생성에 실패했습니다. 왼쪽의 모델 로그나 출력(디버그)에서 내용을 확인하세요.")
    else:
        st.success(f"{len(questions)}문제가 생성되었습니다.")

        # 화면에 출력 및 CSV로 제공
        rows = []
        for idx, q in enumerate(questions, start=1):
            q_type = q.get('type', 'mcq')
            st.markdown(f"**문제 {idx}. ({'객관식' if q_type=='mcq' else '주관식'})**")
            st.write(q.get('question'))
            if q_type == 'mcq':
                choices = q.get('choices', [])
                for ci, ch in enumerate(choices, start=1):
                    st.write(f"   {chr(64+ci)}. {ch}")
            st.write("**정답:**", q.get('answer', ''))
            if q.get('explanation'):
                with st.expander('해설', expanded=False):
                    st.write(q.get('explanation'))

            rows.append({
                'index': idx,
                'type': q_type,
                'question': q.get('question', ''),
                'choices': json.dumps(q.get('choices', []), ensure_ascii=False),
                'answer': q.get('answer', ''),
                'explanation': q.get('explanation', '')
            })

        df = pd.DataFrame(rows)
        csv_io = io.StringIO()
        df.to_csv(csv_io, index=False)
        csv_bytes = csv_io.getvalue().encode('utf-8')

        st.download_button(label="CSV로 내려받기", data=csv_bytes, file_name="generated_questions.csv", mime='text/csv')

# ------------------------- 보조 정보/디버그 -------------------------
with st.expander("디버그: 원문(최대 10000자)"):
    st.write(combined_text[:10000])

with st.expander("도움말"):
    st.write("- 이 페이지는 '이미 업로드된 파일'이 앱에 존재한다고 가정합니다. 업로드 로직은 별도 페이지에서 처리하세요.")
    st.write("- 동영상(mp4)에서 직접 텍스트를 뽑으려면 서버사이드에서 ffmpeg로 오디오를 추출하고 Whisper 또는 OpenAI의 음성-텍스트 API를 호출해야 합니다.")
    st.write("- 문제 출제 스타일/포맷을 바꾸려면 call_gpt_generate_questions의 프롬프트를 수정하세요.")


# 끝
