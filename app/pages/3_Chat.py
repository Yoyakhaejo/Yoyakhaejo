import streamlit as st
st.set_option("client.showErrorDetails", True)
import html

st.title("3. ì±„íŒ…í•˜ê¸°")

from openai import OpenAI


def init_state():
	if "user_api_key" not in st.session_state:
		st.session_state["user_api_key"] = None
	if "uploaded_content" not in st.session_state:
		st.session_state["uploaded_content"] = None
	if "content_type" not in st.session_state:
		st.session_state["content_type"] = None
	if "chat_history" not in st.session_state:
		# list of dicts: {role: 'user'|'assistant', 'content': '...'}
		st.session_state["chat_history"] = []


init_state()


def build_user_input(uploaded_content, content_type: str) -> str:
	"""
	`1_FileUpload.py`ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì—…ë¡œë“œëœ ë‚´ìš©ì„ ëª¨ë¸ì— ë³´ë‚¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
	- text: ì—…ë¡œë“œí•œ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
	- youtube: URLì„ ì „ë‹¬í•˜ê³  ì‹¤ì œ ì˜ìƒ ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•¨ì„ ëª…ì‹œ
	- file: íŒŒì¼ëª…ê³¼ í™•ì¥ìë¥¼ ì „ë‹¬í•˜ì—¬ ì¼ë°˜ì ì¸ ê°•ì˜ ìë£Œë¼ê³  ê°€ì •í•˜ë„ë¡ í•¨
	"""
	if not uploaded_content:
		return ""

	if content_type == "text":
		return (
			"ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” í•œ í¸ì˜ ê°•ì˜ ë‚´ìš©ì„ ì˜®ê²¨ ì ì€ ê²ƒì´ë‹¤. ì´ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì— ì°¸ê³ í•´ì¤˜.\n\n"
			f"{uploaded_content}"
		)

	if content_type == "youtube":
		return (
			"ì‚¬ìš©ìê°€ ì•„ë˜ ìœ íŠœë¸Œ ë§í¬ì˜ ê°•ì˜ë¥¼ ë“¤ì—ˆë‹¤ê³  ê°€ì •í•˜ì. ì‹¤ì œ ì˜ìƒì´ë‚˜ ìë§‰ì— ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ì¼ë°˜ì ì¸ ëŒ€í•™ ê°•ì˜ êµ¬ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\n\n"
			f"ìœ íŠœë¸Œ URL: {uploaded_content}\n\n"
			"â€» ì‹¤ì œ ì˜ìƒ ë‚´ìš©ì€ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ë„ˆë¬´ êµ¬ì²´ì ì¸ ìˆ«ì/ì˜ˆì‹œëŠ” í”¼í•˜ê³  ì „í˜•ì ì¸ ê°•ì˜ êµ¬ì¡°ì— ë§ì¶° ì •ë¦¬í•´ì¤˜."
		)

	# íŒŒì¼(PDF/PPT/ì˜ìƒ ë“±)
	file_name = getattr(uploaded_content, "name", str(uploaded_content))
	ext = "ì•Œìˆ˜ì—†ìŒ"
	try:
		if isinstance(file_name, str) and "." in file_name:
			ext = file_name.split(".")[-1]
	except Exception:
		ext = "ì•Œìˆ˜ì—†ìŒ"

	return (
		"ì‚¬ìš©ìê°€ ëŒ€í•™ ê°•ì˜ìë£Œ íŒŒì¼ì„ ì—…ë¡œë“œí–ˆë‹¤. ì‹¤ì œ íŒŒì¼ ë‚´ìš©ì„ ì§ì ‘ ì½ì„ ìˆ˜ëŠ” ì—†ìœ¼ë¯€ë¡œ, ì¼ë°˜ì ì¸ ëŒ€í•™ ê°•ì˜ ìŠ¬ë¼ì´ë“œ/ìë£Œë¼ê³  ê°€ì •í•˜ê³  ë‹µë³€í•´ì¤˜.\n\n"
		f"íŒŒì¼ ì´ë¦„: {file_name}\n"
		f"íŒŒì¼ íƒ€ì…(í™•ì¥ì): {ext}\n\n"
		"â€» ì‹¤ì œ ìŠ¬ë¼ì´ë“œ ë‚´ìš©ì„ ëª¨ë¥´ëŠ” ìƒíƒœì´ë¯€ë¡œ, ê³¼ë„í•˜ê²Œ êµ¬ì²´ì ì¸ ì˜ˆì‹œëŠ” í”¼í•˜ê³ , ëŒ€í•™ìƒ ëŒ€ìƒì˜ ì¼ë°˜ì ì¸ ê°•ì˜ êµ¬ì¡°ì— ë§ì¶° ë‹µë³€í•´ì¤˜."
	)


# 1_FileUpload í˜ì´ì§€ì—ì„œ ì €ì¥ëœ API Keyì™€ íŒŒì¼ì„ ë°›ì•„ ì—…ë°ì´íŠ¸
user_api_key = st.session_state.get("user_api_key")
uploaded_content = st.session_state.get("uploaded_content")
content_type = st.session_state.get("content_type")

if user_api_key is None or user_api_key == "":
	st.error("â— ë¨¼ì € 1ë²ˆ í˜ì´ì§€ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
	st.stop()

# Warn if no content uploaded (but still allow chat to proceed)
if not uploaded_content:
	st.error("âŒ 1ë²ˆ í˜ì´ì§€ì—ì„œ ë¨¼ì € ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”:\n- ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ (PDF, PPT, ì˜ìƒ)\n- â–¶ï¸ ìœ íŠœë¸Œ ë§í¬\n- ğŸ“ í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥\n\nìë£Œ ì—…ë¡œë“œ í›„ ì±„íŒ…ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
	st.stop()

client = OpenAI(api_key=user_api_key)


def generate_response(client, user_message, history, uploaded_content=None, content_type=None):
	# Prepare system prompt explaining role and use of uploaded materials
	system_prompt = (
		"ë„ˆëŠ” ëŒ€í•™ìƒì„ ë„ì™€ ê³µë¶€ íš¨ìœ¨ì„ ë†’ì—¬ì£¼ëŠ” ì¹œì ˆí•œ íŠœí„°ì•¼.\n"
		"ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ê°•ì˜ìë£Œë¥¼ ì°¸ê³ í•´ì„œ ë‹µë³€ì„ ì£¼ê³ , í•„ìš”í•˜ë©´ ì˜ˆì‹œì™€ ë³µìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì¤˜.\n"
		"ì§§ê³  ëª…í™•í•˜ê²Œ, í•µì‹¬ì„ ìš°ì„ ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜."
	)

	# Build input messages from history (keep recent history)
	messages = [
		{"role": "system", "content": system_prompt},
	]

	# include last N messages to maintain context
	recent = history[-10:] if history else []
	for m in recent:
		role = m.get("role")
		content = m.get("content")
		if role in ("user", "assistant"):
			messages.append({"role": role, "content": content})

	# If there is uploaded content and it's the first message in history, include context once
	if uploaded_content and len(history) == 1:
		uploaded_prompt = build_user_input(uploaded_content, content_type)
		if uploaded_prompt:
			# add as a user message so model can reference it
			messages.append({"role": "user", "content": uploaded_prompt})

	# finally add this user message (the actual question)
	messages.append({"role": "user", "content": user_message})

	# Call OpenAI Chat Completions API
	resp = client.chat.completions.create(
		model="gpt-4o-mini",
		messages=messages,
		temperature=0.2,
	)
	# Some SDK versions return the message differently; handle common shapes
	try:
		return resp.choices[0].message.content
	except Exception:
		# fallback to attribute used by older/newer SDKs
		return getattr(resp, "output_text", str(resp))


# Layout: chat area (scrollable) + fixed-ish input at bottom
# Use a placeholder so we can re-render the chat immediately when messages change
chat_placeholder = st.empty()

def render_chat():
	chat_html = []
	for msg in st.session_state["chat_history"]:
		role = msg.get("role")
		content = msg.get("content")
		safe_content = html.escape(content)
		if role == "user":
			chat_html.append(
				f"<div style='text-align:right; margin:8px 0;'>"
				f"<div style='display:inline-block; background:#DCF8C6; padding:10px 14px; border-radius:12px; max-width:80%;'>{safe_content}</div></div>"
			)
		else:
			chat_html.append(
				f"<div style='text-align:left; margin:8px 0;'>"
				f"<div style='display:inline-block; background:#F1F0F0; padding:10px 14px; border-radius:12px; max-width:80%;'>{safe_content}</div></div>"
			)

	# render within a scrollable box
	chat_box = """
	<div id='chatbox' style='height:60vh; overflow:auto; padding:12px; border:1px solid #e6e6e6; background:#ffffff; border-radius:8px;'>
	"""
	chat_box += "\n".join(chat_html)
	chat_box += "</div>"

	chat_placeholder.markdown(chat_box, unsafe_allow_html=True)

# initial render
render_chat()


# Input area (avoid modifying widget-backed session_state keys after creation)
st.write("")
cols = st.columns([8, 1])
with cols[0]:
	# use the return value of text_input (no direct session_state writes to the widget key)
	user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enter ë˜ëŠ” ì „ì†¡ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”")
with cols[1]:
	send = st.button("ì „ì†¡")

def handle_send(text: str):
	text = (text or "").strip()
	if not text:
		return
	# append user message
	st.session_state["chat_history"].append({"role": "user", "content": text})

	# Immediately re-render chat so user's message appears before AI generation
	render_chat()

	# generate assistant response
	try:
		with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
			reply = generate_response(client, text, st.session_state["chat_history"], uploaded_content, content_type)
	except Exception as e:
		reply = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
		st.error(f"ì˜¤ë¥˜: {e}")

	# append assistant reply and re-render
	st.session_state["chat_history"].append({"role": "assistant", "content": reply})
	render_chat()


if send:
	handle_send(user_input)
	if st.session_state.get("chat_history"):
		st.info("ìœ„ ìŠ¤í¬ë¡¤ ì˜ì—­ì„ ì‚¬ìš©í•´ ëŒ€í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì…ë ¥ì°½ì€ í•­ìƒ í•˜ë‹¨ì— ìˆìŠµë‹ˆë‹¤.")