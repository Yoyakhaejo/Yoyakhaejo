import streamlit as st
from openai import OpenAI
import fitz  # PyMuPDF
import tempfile

st.set_page_config(page_title="Chat - ìš”ì•½í•´ì¤˜", layout="wide")

# --- Session state ê¸°ë³¸ê°’ ë³´ì¥ ---
st.session_state.setdefault("user_api_key", "")
st.session_state.setdefault("uploaded_content", None)
st.session_state.setdefault("content_type", None)


# ------------------------
# í˜ì´ì§€ ì œëª©ê³¼ ì„¤ëª… (í•­ìƒ í‘œì‹œ)
# ------------------------
st.title("AI í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡")
st.write("ì—…ë¡œë“œí•œ í•™ìŠµìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”. ì•„ë˜ ì…ë ¥ì´ ì™„ë£Œë˜ë©´ ì±—ë´‡ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")
st.divider()



# ------------------------
# API KEY í™•ì¸ (íƒ€ì´í‹€ ì•„ë˜ì—ì„œ ê²€ì¦)
# ------------------------
api_key = st.session_state.get("user_api_key", "")
if not api_key:
    st.error("ğŸš¨ API Keyê°€ ì—†ìŠµë‹ˆë‹¤. 1_FileUpload í˜ì´ì§€ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=api_key)


# ------------------------
# ì—…ë¡œë“œ íŒŒì¼ í™•ì¸ (API Key í†µê³¼ í›„)
# ------------------------
uploaded_content = st.session_state.get("uploaded_content", None)
content_type = st.session_state.get("content_type", None)

if uploaded_content is None or content_type is None:
    st.warning("âš  ì•„ì§ í•™ìŠµ ìë£Œê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 1_FileUploadì—ì„œ íŒŒì¼ ë˜ëŠ” ë§í¬ë¥¼ ë“±ë¡í•˜ì„¸ìš”.")
    st.stop()


# ------------------------
# ìë£Œ â†’ í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜
# ------------------------
def extract_text_from_pdf(file_bytes):
    text = ""
    try:
        with fitz.open(stream=file_bytes, filetype="pdf") as pdf:
            for page_num, page in enumerate(pdf):
                text += f"--- Page {page_num + 1} ---\n"
                text += page.get_text()
                text += "\n"
    except Exception as e:
        text = f"[PDF ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}"
    return text


def extract_material_text(uploaded_content, content_type: str) -> str:

    if content_type == "text":
        return uploaded_content
    
    elif content_type == "youtube":
        return f"""
ğŸ“Œ ìœ íŠœë¸Œ ë§í¬: {uploaded_content}

âš  ì˜ìƒ ë‚´ìš©ì€ ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì¼ë°˜ì ì¸ ìœ íŠœë¸Œ ê°•ì˜ í˜•ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
"""
    
    elif content_type == "pdf":
        try:
            pdf_text = extract_text_from_pdf(uploaded_content.getvalue())
            return pdf_text[:8000]  # í† í° ì œí•œ ê³ ë ¤
        except Exception as e:
            return f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
    
    elif content_type in ("ppt", "pptx"):
        return "âš  PPT íŒŒì¼ ìë™ í…ìŠ¤íŠ¸ ì¶”ì¶œì€ ì•„ì§ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìŠ¬ë¼ì´ë“œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•˜ê² ìŠµë‹ˆë‹¤."
    
    elif content_type in ("mp4", "mov", "avi"):
        return "âš  ì˜ìƒ íŒŒì¼ì€ ìë™ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì˜ìƒ ë‚´ìš©ì„ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ì¼ë°˜ì  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤."

    return "ì•Œ ìˆ˜ ì—†ëŠ” ìë£Œ í˜•ì‹ì…ë‹ˆë‹¤."


material_text = extract_material_text(uploaded_content, content_type)

st.info(f"ğŸ“š í˜„ì¬ ìë£Œ ìœ í˜•: **{content_type}**")


# ------------------------
# ì´ˆê¸°í™” ë²„íŠ¼
# ------------------------
if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.pop("messages", None)
    st.rerun()

st.divider()


# ------------------------
# ëŒ€í™” ê¸°ì–µ ê³µê°„
# ------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []


# ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])



# ------------------------
# ì§ˆë¬¸ ì²˜ë¦¬
# ------------------------
query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

if query:
    with st.chat_message("user"):
        st.markdown(query)

    st.session_state.messages.append({"role": "user", "content": query})

    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):

        system_prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ê°•ì˜ ìë£Œ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµì„ ë•ëŠ” AI íŠœí„°ì´ë‹¤.

ìë£Œ ë‚´ìš©:
---
{material_text}
---

ê·œì¹™:
1. ê°•ì˜ ìë£Œ ë‚´ìš© â†’ ìš°ì„  ì´ìš©
2. ì—†ì„ ê²½ìš° ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë³´ì™„
3. í•œêµ­ì–´ë¡œ ë‹µë³€
4. ëª…í™• Â· ì¹œì ˆ Â· ì§§ê²Œ
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                *st.session_state.messages,
            ],
            max_tokens=1500,
            temperature=0.7
        )

        answer = response.choices[0].message.content

        with st.chat_message("assistant"):
            st.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})
